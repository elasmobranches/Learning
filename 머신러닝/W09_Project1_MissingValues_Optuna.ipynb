{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8qyPKIn04QR"
      },
      "source": [
        "# 결측치 처리방식에 따라 달라지는 분류기의 성능 확인\n",
        "\n",
        "\n",
        "## 1. 결측이 발생한 행, 열정보를 삭제하는 방법\n",
        "> - dropna를 활용한 결측치가 존재하는 행 또는 열정보 제거\n",
        ">   - df.dropna(axis=0) # axis=0 열, axis=1 행\n",
        "\n",
        "## 2. 특정 값을 활용한 결측치 처리 방법\n",
        "2-1. fillna(값)를 통한 특정 값으로 채우기\n",
        "> - 0으로 채우기: df.fillna(0)\n",
        "> - 평균 : df.fillna(df.mean())\n",
        "> - 중앙값 : df.fillna(df.median())\n",
        "> - 최빈값 : df.fillna(df.mode())\n",
        "> - 이전행의 값으로 채우기: df.fillna(method='ffill')\n",
        "> - 바로 다음행의 값으로 채우기: df.fillna(method='bfill')\n",
        "\n",
        "2-2. 그룹연산(groupby)으로 분류된 각 그룹 단위의 평균값을 활용하여 채우기\n",
        "> ```\n",
        "> fill_mean_grp = lambda g: g.fillna(g.mean())\n",
        "> df = df.groupby('그룹조건컬럼명').apply(fill_mean_grp)\n",
        "> ```\n",
        "\n",
        "2-3. 간단한 선형비례를 이용하여 대체하는 방법\n",
        "> - df = df.interpolate(method='values')\n",
        "\n",
        "\n",
        "## 3. 다른 알고리즘를 활용한 결측치 처리 방법\n",
        "- KNN을 활용하여 유사한 패턴을 보이는 데이터의 값을 참고하여 대체 <br>\n",
        "  이때 column 및 index값이 숫자로 변경됨\n",
        "> ```\n",
        "> imputer = KNNImputer(n_neighbors=3) # n_neighbors: 결측치 처리에 참고할 이웃값 수\n",
        "> knn_data = pd.DataFrame(imputer.fit_transform(df))\n",
        "> ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckZe6lJjxR0N"
      },
      "source": [
        "# 1. 결측이 발생한 행 또는 열정보 제거: dropna(axis=축방향)\n",
        "- axis=0 # 열 제거\n",
        "- axis=1 # 행 제거\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg7uWghksvd5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 출력 표기 생략\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 데이터 불러오기\n",
        "# 파일 경로 = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\"\n",
        "married_dataset = pd.read_csv(\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\")\n",
        "\n",
        "#한번에 생략없이 출력하고 싶은 컬럼 수 설정\n",
        "#pd.options.display.max_columns = 25\n",
        "\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EBd9wBatAWu"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 결측치 수 확인\n",
        "married_dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCi6bkIrtbKG"
      },
      "outputs": [],
      "source": [
        "# 항목별 결측치 비율 확인\n",
        "married_dataset.isna().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU6zVEW_tdt4"
      },
      "outputs": [],
      "source": [
        "# 결측치를 제거하여 처리\n",
        "married_dataset = married_dataset.dropna(axis=0)\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRl4-BpIth5e"
      },
      "outputs": [],
      "source": [
        "# object 타입의 문자열 변수를 숫자형으로 변환\n",
        "married_dataset = pd.get_dummies(married_dataset, columns=['gender'], drop_first=True)\n",
        "\n",
        "# 데이터셋, 독립변수와 종속변수 분리: 독립변수 -> x, 종속변수 -> y\n",
        "x = married_dataset.drop(['married'], axis=1)\n",
        "y = married_dataset['married']\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5QSoQSatspm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_test_split를 활용한 train set, test set 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiBf0AQWtv_l"
      },
      "outputs": [],
      "source": [
        "# 예시로 xgboost 활용\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# model = xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=100)\n",
        "model = xgb.XGBClassifier(random_state=100)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7bleDGvtxl0"
      },
      "outputs": [],
      "source": [
        "# 테스트 데이터로 예측\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, pred)  # accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M05HzoXct0hM"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test, pred))  # confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdt7r48Ht2iX"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred))  # classification repor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovuYQxNexIPx"
      },
      "source": [
        "# 2. 특정 값을 활용한 결측치 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z2Fzk_6y6k9"
      },
      "source": [
        "## 2-1. fillna(값)를 통한 특정 값으로 채우기\n",
        "> - 0으로 채우기: df.fillna(0)\n",
        "> - 평균 : df.fillna(df.mean())\n",
        "> - 중앙값 : df.fillna(df.median())\n",
        "> - 최빈값 : df.fillna(df.mode())\n",
        "> - 이전행의 값으로 채우기: df.fillna(method='ffill')\n",
        "> - 바로 다음행의 값으로 채우기: df.fillna(method='bfill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0DQv1shxdZM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 출력 표기 생략\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 데이터 불러오기\n",
        "# 파일 경로 = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\"\n",
        "married_dataset = pd.read_csv(\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\")\n",
        "\n",
        "#한번에 생략없이 출력하고 싶은 컬럼 수 설정\n",
        "#pd.options.display.max_columns = 25\n",
        "\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwa5_n3txdZN"
      },
      "outputs": [],
      "source": [
        "# object 타입의 문자열 변수를 숫자형으로 변환\n",
        "married_dataset = pd.get_dummies(married_dataset, columns=['gender'], drop_first=True)\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07J3vrYmxdZN"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "0으로 채우기: df.fillna(0)\n",
        "평균 : df.fillna(df.mean())\n",
        "중앙값 : df.fillna(df.median())\n",
        "최빈값 : df.fillna(df.mode())\n",
        "이전행의 값으로 채우기: df.fillna(method='ffill')\n",
        "바로 다음행의 값으로 채우기: df.fillna(method='bfill')\n",
        "'''\n",
        "\n",
        "married_dataset = married_dataset.fillna(married_dataset.median()) #변경 가능\n",
        "\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUm5ac8UYMYx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋, 독립변수와 종속변수 분리: 독립변수 -> x, 종속변수 -> y\n",
        "x = married_dataset.drop(['married'], axis=1)\n",
        "y = married_dataset['married']\n",
        "\n",
        "# train_test_split를 활용한 train set, test set 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWcDzmR1YMY2"
      },
      "outputs": [],
      "source": [
        "# 예시로 xgboost 활용\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# model = xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=100)\n",
        "model = xgb.XGBClassifier(random_state=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, pred)  # accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gNdfK2g1xgk"
      },
      "source": [
        "## 2-2. 그룹연산(groupby)으로 분류된 각 그룹 단위의 평균값을 활용한 결측치 처리\n",
        "> ```\n",
        "> fill_mean_grp = lambda g: g.fillna(g.mean())\n",
        "> df = df.groupby('그룹조건컬럼명').apply(fill_mean_grp)\n",
        "> ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku69U6642tVE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 출력 표기 생략\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 데이터 불러오기\n",
        "# 파일 경로 = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\"\n",
        "married_dataset = pd.read_csv(\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\")\n",
        "\n",
        "#한번에 생략없이 출력하고 싶은 컬럼 수 설정\n",
        "#pd.options.display.max_columns = 25\n",
        "\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz66pmxtEAL8"
      },
      "outputs": [],
      "source": [
        "# object 타입의 문자열 변수를 숫자형으로 변환\n",
        "married_dataset = pd.get_dummies(married_dataset, columns=['gender'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d46hFcSs2uVR"
      },
      "outputs": [],
      "source": [
        "# 결혼 성공 여부에 따라 그룹화 하여 해당 그룹내 각 컬럼별 평균값으로 결측치 처리\n",
        "fill_mean_grp = lambda g: g.fillna(g.mean())\n",
        "married_grp_mean = married_dataset.groupby('married').apply(fill_mean_grp)\n",
        "\n",
        "married_grp_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGlIykBIYduj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋, 독립변수와 종속변수 분리: 독립변수 -> x, 종속변수 -> y\n",
        "x = married_grp_mean.drop(['married'], axis=1)\n",
        "y = married_grp_mean['married']\n",
        "\n",
        "# train_test_split를 활용한 train set, test set 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eb3ArwmYduk"
      },
      "outputs": [],
      "source": [
        "# 예시로 xgboost 활용\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# model = xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=100)\n",
        "model = xgb.XGBClassifier(random_state=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, pred)  # accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZsRzbNM3MCN"
      },
      "source": [
        "## 2-3. 간단한 선형비례를 이용하여 대체하는 방법\n",
        "\n",
        "df = df.interpolate(method='values')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWgDto8C3PmG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 출력 표기 생략\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 데이터 불러오기\n",
        "# 파일 경로 = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\"\n",
        "married_dataset = pd.read_csv(\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\")\n",
        "\n",
        "#한번에 생략없이 출력하고 싶은 컬럼 수 설정\n",
        "#pd.options.display.max_columns = 25\n",
        "\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5yc-0osEHL9"
      },
      "outputs": [],
      "source": [
        "# object 타입의 문자열 변수를 숫자형으로 변환\n",
        "married_dataset = pd.get_dummies(married_dataset, columns=['gender'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1XwnQb7ENFF"
      },
      "outputs": [],
      "source": [
        "married_dataset = married_dataset.interpolate(method='values')\n",
        "\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOipFWfaY6WF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋, 독립변수와 종속변수 분리: 독립변수 -> x, 종속변수 -> y\n",
        "x = married_dataset.drop(['married'], axis=1)\n",
        "y = married_dataset['married']\n",
        "\n",
        "# train_test_split를 활용한 train set, test set 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wBveF5gY6XP"
      },
      "outputs": [],
      "source": [
        "# 예시로 xgboost 활용\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# model = xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=100)\n",
        "model = xgb.XGBClassifier(random_state=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, pred)  # accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFL4lfbmEv0l"
      },
      "source": [
        "# 3. 다른 알고리즘를 활용한 결측치 처리 방법: KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YplShlZL2ax4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 출력 표기 생략\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 데이터 불러오기\n",
        "# 파일 경로 = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\"\n",
        "married_dataset = pd.read_csv(\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\")\n",
        "\n",
        "#한번에 생략없이 출력하고 싶은 컬럼 수 설정\n",
        "#pd.options.display.max_columns = 25\n",
        "\n",
        "married_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xZtA4GNFU5c"
      },
      "outputs": [],
      "source": [
        "# object 타입의 문자열 변수를 숫자형으로 변환\n",
        "married_dataset = pd.get_dummies(married_dataset, columns=['gender'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9n7nkpdvMtk"
      },
      "outputs": [],
      "source": [
        "# 사이킷런 라이브러리의 KNNImputer 불러오기\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# KNNImputer 객체 생성과 KNN알고리즘에서 중요한 n_neighbors 수(참고할 이웃값 수) 설정\n",
        "imputer = KNNImputer(n_neighbors=3)\n",
        "\n",
        "married_knn = pd.DataFrame(imputer.fit_transform(married_dataset))\n",
        "married_knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APgQzX0SFyT2"
      },
      "outputs": [],
      "source": [
        "# 컬럼명이 숫자로 변환되었으므로 다시 원래의 이름으로 변환\n",
        "married_knn.columns = married_dataset.columns\n",
        "\n",
        "married_knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obj21t9FGLZq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋, 독립변수와 종속변수 분리: 독립변수 -> x, 종속변수 -> y\n",
        "x = married_knn.drop(['married'], axis=1)\n",
        "y = married_knn['married']\n",
        "\n",
        "# train set 과 test set 으로 데이터를 나누기 위해 train_test_split 활용\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GstmC-G1vSjE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# model = xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=100)\n",
        "model = xgb.XGBClassifier(random_state=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print('accuracy:',accuracy_score(y_test, pred))\n",
        "print('f1-score:',f1_score(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS2lH_T2vVr7"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test, pred))  # confusion matrix 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7OjVJuavXEC"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred))  # classification report 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FGF_8dnvh31"
      },
      "source": [
        "# 하이퍼파라미터 튜닝\n",
        "\n",
        "- optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8tgSITXwLN_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 출력 표기 생략\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 데이터 불러오기\n",
        "# 파일 경로 = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\"\n",
        "married_dataset = pd.read_csv(\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\")\n",
        "\n",
        "# object 타입의 문자열 변수를 숫자형으로 변환\n",
        "married_dataset = pd.get_dummies(married_dataset, columns=['gender'], drop_first=True)\n",
        "\n",
        "# 데이터셋, 독립변수와 종속변수 분리: 독립변수 -> x, 종속변수 -> y\n",
        "x = married_dataset.drop(['married'], axis=1)\n",
        "y = married_dataset['married']\n",
        "\n",
        "# train set 과 test set 으로 데이터를 나누기 위해 train_test_split 함수를 불러옴\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Cykyr76wLOg"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "model = xgb.XGBClassifier(random_state=100)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv1SKa3cwLOh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print('accuracy:',accuracy_score(y_test, pred))\n",
        "print('f1-score:',f1_score(y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqE3ArvFCpIF"
      },
      "source": [
        "### XGBoost Classifier에 있는 Hyperparameter\n",
        "* XGBoost API 설명자료: https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.sklearn  \n",
        "\n",
        "* 코드에서 활용한 하이퍼 파라미터\n",
        "> * objective: 모델의 학습 과제 및 학습목표(일반적으로 classifier의 경우 이진 혹은 다중 분류로 기본값이 설정되어 있음)\n",
        "> * num_leaves: tree의 최대 leaf 수\n",
        "> * learning_rate: 학습률\n",
        "> * n_estimators: 학습에 사용할 트리 수(xgb학습과정에서 부스팅 라운드 수)\n",
        "> * max_depth: 트리의 최대 깊이\n",
        "> * ramdom_state: 결과 재현을 위한 시드값\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sP0_8W1a6gk"
      },
      "outputs": [],
      "source": [
        "#현재 코랩 런타임에 Optuna 라이브러리 설치\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa2RjPoD048N"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    global X_train, X_test, y_train, y_test\n",
        "    xbg_trainset = xgb.DMatrix(X_train, label=y_train)\n",
        "    xgb_testset = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # 최적화할 하이퍼 파라미터 지정 및 찾아볼 값 범위 설정\n",
        "    param = {\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 1024, step=1, log=True),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 0.3),\n",
        "        'n_estimators':  trial.suggest_int('n_estimators',100,3000 ),\n",
        "        'max_depth': trial.suggest_int(\"max_depth\", 3, 21, step=2),\n",
        "        'random_state': 100,\n",
        "    }\n",
        "\n",
        "    model_train = xgb.train(param, xbg_trainset)\n",
        "    preds = model_train.predict(xgb_testset)\n",
        "    pred_labels = np.rint(preds)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, pred_labels)\n",
        "    return accuracy\n",
        "\n",
        "# optuna에서의 최적화 할 study 생성과 최적화 방향(지표의 값을 최대화 할 것인지)\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "# trial 횟수 설정 및 최적화 시작\n",
        "study.optimize(objective, n_trials=500, timeout=600)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Amx5ED6qbYnP"
      },
      "outputs": [],
      "source": [
        "# best trial에 대한 성능과 hyperparameter 정보 출력\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ijj7zSF46rjT"
      },
      "outputs": [],
      "source": [
        "#plot_optimization_histor: trial 진행과정 히스토리\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnAI3U9e7AOC"
      },
      "outputs": [],
      "source": [
        "#plot_parallel_coordinate: 하이퍼파라미터의 조합과 점수에 대한 시각화\n",
        "optuna.visualization.plot_parallel_coordinate(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGBLECBx7Fwy"
      },
      "outputs": [],
      "source": [
        "#최적화 과정에서 계산된 하이퍼 파라미터 별 성능에 영향을 미친 중요도 시각화\n",
        "optuna.visualization.plot_param_importances(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4m8IRxTIcr4"
      },
      "source": [
        "# [추가실습자료] LightGBM 알고리즘 활용하기 + optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY5pms8IJf3p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 출력 표기 생략\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 파일 경로 = \"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\"\n",
        "married_dataset = pd.read_csv(\"https://raw.githubusercontent.com/agtechresearch/LectureAlgorithm/main/csv/married_full.csv\")\n",
        "\n",
        "# 결측치 처리\n",
        "married_dataset = married_dataset.dropna(axis=0)\n",
        "\n",
        "# object 타입의 문자열 변수를 숫자형으로 변환\n",
        "married_dataset = pd.get_dummies(married_dataset, columns=['gender'], drop_first=True)\n",
        "\n",
        "# 데이터셋, 독립변수와 종속변수 분리: 독립변수 -> x, 종속변수 -> y\n",
        "x = married_dataset.drop(['married'], axis=1)\n",
        "y = married_dataset['married']\n",
        "\n",
        "# train set 과 test set 으로 데이터를 나누기 위해 train_test_split 함수를 불러옴\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niN_n9qDKU2_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "model = lgb.LGBMClassifier(random_state=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)  # 테스트 데이터로 예측\n",
        "\n",
        "print('accuracy:',accuracy_score(y_test, pred))\n",
        "print('f1-score:',f1_score(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TEKd6XPMQyU"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test, pred))  # confusion matrix 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvhZI3YKMQyV"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred))  # classification report 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r35yfxuAEuDR"
      },
      "source": [
        "### LightGBM Classifier에 있는 Hyperparameter\n",
        "- LightGBMClassifier : https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier\n",
        "- 코드에서 활용한 하이퍼파라미터\n",
        "> * objective: 모델의 학습 과제 및 학습목표(일반적으로 classifier의 경우 이진 혹은 다중 분류로 기본값이 설정되어 있음)\n",
        "> * num_leaves: tree의 최대 leaf 수\n",
        "> * learning_rate: 학습률\n",
        "> * n_estimators: 학습에 사용할 트리 수\n",
        "> * max_depth: 트리의 최대 깊이\n",
        "> * ramdom_state: 결과 재현을 위한 시드값\n",
        "\n",
        "- 아래 문구가 학습시 나오더라도 오류는 아니니 무시할 것(더 분할할 수 없어서 나타나는 경고)\n",
        "\n",
        "  [Warning] No further splits with positive gain, best gain: -inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNsHTl0HMYwV"
      },
      "outputs": [],
      "source": [
        "# Optuna\n",
        "import optuna\n",
        "def objective(trial):\n",
        "    global X_train, X_test, y_train, y_test\n",
        "\n",
        "    # 최적화 할 하이퍼파라미터 지정 및 값의 범위 설정\n",
        "    param = {\n",
        "        \"objective\": \"binary\",\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 512, step=1, log=True),\n",
        "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 0.3),\n",
        "        'n_estimators':  trial.suggest_int('n_estimators',100,1000 ),\n",
        "        'max_depth': trial.suggest_int(\"max_depth\", 3, 21, step=2),\n",
        "        'random_state': 100,\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMRegressor(**param)\n",
        "    lgb_model = model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
        "    preds = lgb_model.predict(X_test)\n",
        "    pred_labels = np.rint(preds)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, pred_labels)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# optuna에서의 최적화 할 study 생성과 최적화 방향(지표의 값을 최대화 할 것인지)\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "# trial 횟수 설정 및 최적화 시작\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLmTJ1nMbfzP"
      },
      "outputs": [],
      "source": [
        "# best trial에 대한 성능과 hyperparameter 정보 출력\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjEsZRYNYve3"
      },
      "outputs": [],
      "source": [
        "#plot_optimization_history\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKS6uxc4Yve4"
      },
      "outputs": [],
      "source": [
        "#plot_parallel_coordinate\n",
        "optuna.visualization.plot_parallel_coordinate(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H78Rv6HBYrOK"
      },
      "outputs": [],
      "source": [
        "#Visualize parameter importances.\n",
        "optuna.visualization.plot_param_importances(study)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}