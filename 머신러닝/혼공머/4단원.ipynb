{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4단원\n",
    "\n",
    "### 로지스틱 회귀\n",
    "\n",
    "타깃 데이터에 2개 이상의 클래스가 포함된 문제를 **다중 분류**라고 부른다\n",
    "\n",
    "이름은 회귀이지만 분류 모델\n",
    "\n",
    "선형 회귀와 동일하게 선형 방정식을 학습한다 선형 방정식의 결과값이\n",
    "\n",
    "0에서 1사이로 만들어 확률값으로 만들기 위해  시그모이드 함수를 사용\n",
    "이진 분류일 경우 0.5가 기준\n",
    "\n",
    "넘파이 배열은 True, False 값을 전달하여 행을 선택한다 ⇒ **불리언 인덱싱**\n",
    "\n",
    "사이킷런은 타깃값을 알파벳순으로 정렬하여 사용한다\n",
    "\n",
    "### 로지스틱 회귀로 다중 분류 수행하기\n",
    "\n",
    "LogisticRegression 클래스는 기본적으로 반복적인 알고리즘을 사용한다\n",
    "\n",
    "max_iter에서 반복 횟수를 지정하며 기본값은 100\n",
    "\n",
    "또한 릿지, 라쏘와 같이 계수의 제곱을 규제하는데 이를 L2 규제라고 한다\n",
    "\n",
    "매개변수는 C이며 기본값은 1, 작을수록 규제가 커진다\n",
    "\n",
    "### 이진 분류 ⇒ 시그모이드 다중 분류⇒ 소프트맥스\n",
    "\n",
    "### 점진적 학습\n",
    "\n",
    "앞서 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 더 훈련한다\n",
    "\n",
    "이런 식의 훈련 방식을 점진적 학습 또는 온라인 학습이라고 부른다\n",
    "\n",
    "대표적인 것이 **확률적 경사 하강법**\n",
    "\n",
    "훈련 세트에서 랜덤하게 하나의 샘플을 선택하여 가파른 경사를 내려간다. 그 다음 훈련 세트에서 랜덤하게 또 다른 샘플을 선택하여 경사를 내려간다→ 샘플을 다 사용할 때 까지\n",
    "\n",
    "훈련 세트를 한 번 모두 사용하는 과정을 **에포크**\n",
    "\n",
    "무작위로 몇 개의 샘플을 선택해서 경사를 따라 내려가는 방법 : **미니배치 경사 하강법**\n",
    "\n",
    "한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용하는 방법 : **배치 경사 하강법**\n",
    "\n",
    "### 손실 함수\n",
    "\n",
    "어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준\n",
    "\n",
    "손실 함수 - 샘플 하나에 대한 손실\n",
    "\n",
    "비용 함수 - 훈련 세트 내 모든 샘플에 대한 손실\n",
    "\n",
    "분류에서의 손실은 정답을 맞히지 못하는 것\n",
    "\n",
    "이진 분류의 손실 함수는 로지스틱 손실 함수\n",
    "\n",
    "다중 분류의 손실 함수는 크로스엔트로피 손실 함수\n",
    "\n",
    "회귀의 손실 함수는 평균 절댓값 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런에서 확률적 경사 하강법을 제공하는 대표적인 분류용 클래스는\n",
    "\n",
    "SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미니배치나 배치 경사 하강법을 제공하지는 않는다\n",
    "\n",
    "과대적합이 시작하기 전에 훈련을 멈추는 것을 **조기 종료**라고 한다\n",
    "\n",
    "SDGClassifier는 일정 에포크 동안 성능이 향상되지 않으면 더 훈련하지 않고 자동으로 멈춘다\n",
    "\n",
    "tol 매개변수에 향상될 최솟값을 지정한다"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
