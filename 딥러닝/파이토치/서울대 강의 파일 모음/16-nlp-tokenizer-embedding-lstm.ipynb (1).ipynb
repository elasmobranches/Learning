{"cells":[{"cell_type":"markdown","id":"67d80b85","metadata":{"id":"67d80b85"},"source":["## 시드 고정\n"]},{"cell_type":"code","execution_count":null,"id":"1c2300df","metadata":{"id":"1c2300df"},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import torch\n","\n","# 시드설정\n","SEED = 123\n","\n","\n","def seed_everything(seed=SEED):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","\n","seed_everything(SEED)"]},{"cell_type":"markdown","id":"744dbbce","metadata":{"id":"744dbbce"},"source":["## 샘플 예제파일 다운로드\n"]},{"cell_type":"code","execution_count":null,"id":"e1ecbacf","metadata":{"id":"e1ecbacf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709033454469,"user_tz":-540,"elapsed":1279,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"5a840cef-afe5-484b-a95f-795c65e65950"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('sarcasm.json', <http.client.HTTPMessage at 0x7c652a41aa10>)"]},"metadata":{},"execution_count":2}],"source":["import urllib\n","\n","url = \"https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json\"\n","urllib.request.urlretrieve(url, \"sarcasm.json\")"]},{"cell_type":"markdown","id":"a95ce279","metadata":{"id":"a95ce279"},"source":["## 데이터 로드\n"]},{"cell_type":"code","execution_count":null,"id":"0e335ef3","metadata":{"id":"0e335ef3","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1709033462875,"user_tz":-540,"elapsed":544,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"81f4ab69-ee27-457f-8955-2685a39b0fde"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        article_link  \\\n","0  https://www.huffingtonpost.com/entry/versace-b...   \n","1  https://www.huffingtonpost.com/entry/roseanne-...   \n","2  https://local.theonion.com/mom-starting-to-fea...   \n","3  https://politics.theonion.com/boehner-just-wan...   \n","4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n","\n","                                            headline  is_sarcastic  \n","0  former versace store clerk sues over secret 'b...             0  \n","1  the 'roseanne' revival catches up to our thorn...             0  \n","2  mom starting to fear son's web series closest ...             1  \n","3  boehner just wants wife to listen, not come up...             1  \n","4  j.k. rowling wishes snape happy birthday in th...             0  "],"text/html":["\n","  <div id=\"df-aefa215e-46f8-4734-a582-1aa66e374409\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_link</th>\n","      <th>headline</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n","      <td>former versace store clerk sues over secret 'b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n","      <td>the 'roseanne' revival catches up to our thorn...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n","      <td>mom starting to fear son's web series closest ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://politics.theonion.com/boehner-just-wan...</td>\n","      <td>boehner just wants wife to listen, not come up...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n","      <td>j.k. rowling wishes snape happy birthday in th...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aefa215e-46f8-4734-a582-1aa66e374409')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-aefa215e-46f8-4734-a582-1aa66e374409 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-aefa215e-46f8-4734-a582-1aa66e374409');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0213dd76-5267-48b7-af4d-9e8bb0e41743\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0213dd76-5267-48b7-af4d-9e8bb0e41743')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0213dd76-5267-48b7-af4d-9e8bb0e41743 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 26709,\n  \"fields\": [\n    {\n      \"column\": \"article_link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26708,\n        \"samples\": [\n          \"https://www.theonion.com/isis-recruiter-excited-to-be-talking-to-popular-high-sc-1819579508\",\n          \"https://www.huffingtonpost.com/entry/jimmy-fallon-could-barely-keep-it-together-during-this-cardi-b-interview_us_5a3c01aae4b06d1621b2de98\",\n          \"https://www.huffingtonpost.com/entry/4-ways-to-support-farmtos_b_5906452.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26602,\n        \"samples\": [\n          \"departing employee not quite important enough for send-off\",\n          \"college student still managing to look like asshole in picture of village he helped build\",\n          \"fun sticker placed on child's ventilator\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}],"source":["import json\n","import pandas as pd\n","\n","with open(\"sarcasm.json\") as f:\n","    datas = json.load(f)\n","\n","df = pd.DataFrame(datas)\n","df.head()"]},{"cell_type":"code","source":["print(df.iloc[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snGZ8UFYV2Pw","executionInfo":{"status":"ok","timestamp":1709033664022,"user_tz":-540,"elapsed":7,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"e107d524-3afd-4675-905c-6f7b5c974e6a"},"id":"snGZ8UFYV2Pw","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["article_link    https://www.huffingtonpost.com/entry/versace-b...\n","headline        former versace store clerk sues over secret 'b...\n","is_sarcastic                                                    0\n","Name: 0, dtype: object\n"]}]},{"cell_type":"markdown","id":"879d2859","metadata":{"id":"879d2859"},"source":["## 토큰화 (Word Tokenization)\n","\n","- get_tokenizer로 토크나이저 생성\n","- `basic_english`, `spacy`, `revtok`, `subword` 등 지정이 가능하나, 몇몇 토크나이저는 추가 라이브러리 설치가 필요합니다.\n"]},{"cell_type":"code","execution_count":null,"id":"e67344a7","metadata":{"id":"e67344a7"},"outputs":[],"source":["# torchtext 설치\n","# !pip install torchtext"]},{"cell_type":"code","execution_count":null,"id":"3925477a","metadata":{"id":"3925477a"},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","\n","# 토큰 생성: 단어별로 쪼갠다.\n","tokenizer = get_tokenizer(\"basic_english\") # 한글 전용 토크나이저도 있다. KoNLP"]},{"cell_type":"markdown","id":"cecede1d","metadata":{"id":"cecede1d"},"source":["토큰화한 결과는 특수문자는 개별 토큰으로 처리, 모든 단어는 소문자로 처리됩니다.\n"]},{"cell_type":"code","execution_count":null,"id":"2387722f","metadata":{"id":"2387722f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709033673025,"user_tz":-540,"elapsed":485,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"b4b9f7ce-03f3-48d6-8d39-7e89bd227ab3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hi', ',', 'my', 'name', 'is', 'teddy', '!', '!', '!']"]},"metadata":{},"execution_count":8}],"source":["tokenizer(\"Hi, my name is Teddy!!!\")"]},{"cell_type":"code","execution_count":null,"id":"35da33b2","metadata":{"id":"35da33b2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709033675622,"user_tz":-540,"elapsed":4,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"7196449f-1bbc-44da-8765-9876dec65bed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hello', ',', 'i', 'would', 'love', 'to', 'learn', 'python', '!']"]},"metadata":{},"execution_count":9}],"source":["tokenizer(\"Hello, I would love to learn Python!\")"]},{"cell_type":"code","execution_count":null,"id":"c123f627","metadata":{"id":"c123f627","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709033677539,"user_tz":-540,"elapsed":3,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"55afb2d7-2293-486e-9033-16828353d613"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['안녕하세요', '?', '한글', '데이터에', '대한', '토큰', '처리는', '어떨까요', '?', '?']"]},"metadata":{},"execution_count":10}],"source":["tokenizer(\"안녕하세요? 한글 데이터에 대한 토큰 처리는 어떨까요??\")"]},{"cell_type":"markdown","id":"33d8f542","metadata":{"id":"33d8f542"},"source":["## 단어사전 생성\n"]},{"cell_type":"code","execution_count":null,"id":"fae2553f","metadata":{"id":"fae2553f"},"outputs":[],"source":["from torchtext.vocab import build_vocab_from_iterator\n","\n","\n","def yield_tokens(sentences):\n","    for text in sentences:\n","        yield tokenizer(text)"]},{"cell_type":"markdown","id":"fd2fe439","metadata":{"id":"fd2fe439"},"source":["`build_vocab_from_iterator` 를 활용하여 단어 사전을 생성합니다.\n","\n","- `min_freq`: 최소 빈도의 토큰의 개수를 입력합니다.\n","- `max_tokens`: 최대 빈도 토큰의 수를 한정합니다. 빈도수 기준으로 산정합니다.\n"]},{"cell_type":"code","execution_count":null,"id":"71928f6c","metadata":{"id":"71928f6c"},"outputs":[],"source":["vocab = build_vocab_from_iterator(\n","    yield_tokens(df[\"headline\"].tolist()),  # 텍스트 Iterator\n","    # 스페셜 토큰 - 모르는 단어 치환\n","    specials=[\"<UNK>\"],\n","    min_freq=2,  # 최소 빈도 토큰(최소 2개 이상 나와야 쓰겠다)\n","    max_tokens=1000,  # 최대 토큰 개수\n",")\n","\n","'''\n"," # 나머지 단어들은 어디로? 그럼 정보의 손실은?\n"," - 모든 단어를 토큰으로 쓰지는 않음. 모든 단어들이 다 중요하진 않다. 고려해야 할 단어의 수를 줄여주는 것, 연산도 줄여 효율적인 학습을 하고자 한다.\n"," 일정 수준으로 만들어줌\n"," - 뽑는 것은 빈도수, 자주나오는 중요 단어를 위주로 설정하는 것. 나머지는 0의 값으로 채워짐.\n","'''\n","\n","vocab.set_default_index(vocab[\"<UNK>\"])"]},{"cell_type":"code","execution_count":null,"id":"75bb7cb3","metadata":{"id":"75bb7cb3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709033818637,"user_tz":-540,"elapsed":2,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"36878bcc-4d21-47cf-c766-153c03faf9f3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":17}],"source":["# 전체 단어사전의 개수 출력\n","len(vocab)"]},{"cell_type":"code","execution_count":null,"id":"05274e5f","metadata":{"id":"05274e5f"},"outputs":[],"source":["# string -> index\n","stoi = vocab.get_stoi()\n","# index -> string\n","itos = vocab.get_itos()"]},{"cell_type":"code","execution_count":null,"id":"fa77b09a","metadata":{"id":"fa77b09a","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1709034124494,"user_tz":-540,"elapsed":488,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"9bbec0e2-3d52-4358-fbbb-33415b785894"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<UNK>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}],"source":["itos[0]"]},{"cell_type":"code","execution_count":null,"id":"a837cfe7","metadata":{"id":"a837cfe7","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1709034134691,"user_tz":-540,"elapsed":502,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"6d5a4155-db93-4372-9c8b-60e41eb5e4d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'trump'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}],"source":["itos[15]"]},{"cell_type":"code","execution_count":null,"id":"00a18451","metadata":{"id":"00a18451","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034150015,"user_tz":-540,"elapsed":506,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"3e01f363-eb12-4cbc-b2f8-5580b5e5fd48"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":21}],"source":["stoi[\"trump\"]"]},{"cell_type":"code","execution_count":null,"id":"20d6abfd","metadata":{"id":"20d6abfd"},"outputs":[],"source":["sample_sentence = \"Hello, I am Teddy. Nice to meet you!!\""]},{"cell_type":"code","execution_count":null,"id":"faacd2df","metadata":{"id":"faacd2df","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034157111,"user_tz":-540,"elapsed":5,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"b443a75f-0334-4297-9387-485c3cea3863"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hello', ',', 'i', 'am', 'teddy', '.', 'nice', 'to', 'meet', 'you', '!', '!']"]},"metadata":{},"execution_count":23}],"source":["tokenizer(sample_sentence)"]},{"cell_type":"code","execution_count":null,"id":"3412b22c","metadata":{"id":"3412b22c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034162197,"user_tz":-540,"elapsed":635,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"4e0f50ec-80a6-4994-cef9-c3f47c8fd891"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 7, 50, 0, 0, 11, 0, 2, 423, 20, 141, 141]"]},"metadata":{},"execution_count":24}],"source":["vocab(tokenizer(sample_sentence))  # 0은 빈도수가 낮거나 사전에 없는 단어"]},{"cell_type":"markdown","id":"8fbc69ea","metadata":{"id":"8fbc69ea"},"source":["## Dataset 분할\n"]},{"cell_type":"code","execution_count":null,"id":"1661ceef","metadata":{"id":"1661ceef"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(\n","    df[\"headline\"],\n","    df[\"is_sarcastic\"],\n","    stratify=df[\"is_sarcastic\"],\n","    test_size=0.2,\n","    random_state=SEED,\n",")"]},{"cell_type":"markdown","id":"26ab9433","metadata":{"id":"26ab9433"},"source":["## Dataset 생성\n"]},{"cell_type":"code","execution_count":null,"id":"b0bff8f3","metadata":{"id":"b0bff8f3"},"outputs":[],"source":["from torch.utils.data import DataLoader, Dataset\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, texts, labels, vocab, tokenizer):\n","        super().__init__()\n","        self.texts = texts\n","        self.labels = labels\n","        self.vocab = vocab\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts.iloc[idx]\n","        label = self.labels.iloc[idx]\n","        return self.vocab(self.tokenizer(text)), label"]},{"cell_type":"code","execution_count":null,"id":"c91f1798","metadata":{"id":"c91f1798"},"outputs":[],"source":["# Custom Dataset 생성\n","train_ds = CustomDataset(x_train, y_train, vocab=vocab, tokenizer=tokenizer)\n","valid_ds = CustomDataset(x_test, y_test, vocab=vocab, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"0f6973b9","metadata":{"id":"0f6973b9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034254515,"user_tz":-540,"elapsed":504,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"e4cb5d35-3ccd-4f5f-b280-270f829493b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 1)"]},"metadata":{},"execution_count":28}],"source":["# 1개의 데이터 추출\n","text, label = next(iter(train_ds))\n","len(text), label"]},{"cell_type":"code","execution_count":null,"id":"71fb33e1","metadata":{"id":"71fb33e1"},"outputs":[],"source":["# iterator 생성\n","iterator = iter(train_ds)"]},{"cell_type":"code","execution_count":null,"id":"133dd423","metadata":{"id":"133dd423","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034260348,"user_tz":-540,"elapsed":732,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"7a6227e1-a2b4-4dcb-f1f3-728e264fbf4a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["([0, 0, 0, 262, 142, 214, 925, 186, 32, 0], 1)"]},"metadata":{},"execution_count":30}],"source":["# Next 로 순회하면서 1개씩 출력\n","next(iterator)"]},{"cell_type":"code","source":["text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHqsgU6RYdrK","executionInfo":{"status":"ok","timestamp":1709034305751,"user_tz":-540,"elapsed":2,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"195dec98-35f4-4263-f632-26e2c8f02e86"},"id":"QHqsgU6RYdrK","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 0, 262, 142, 214, 925, 186, 32, 0]"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","id":"de142034","metadata":{"id":"de142034"},"source":["## DataLoader 생성\n"]},{"cell_type":"markdown","id":"74296405","metadata":{"id":"74296405"},"source":["GPU 를 설정합니다\n"]},{"cell_type":"code","execution_count":null,"id":"ed101327","metadata":{"id":"ed101327","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034313493,"user_tz":-540,"elapsed":501,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"9f146a30-5276-4f0a-feac-eea378197198"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["# CUDA 사용 가능 여부 확인\n","if torch.backends.mps.is_built():\n","    # mac os mps 지원 체크\n","    device = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n","else:\n","    # cuda 사용 가능한지 체크\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","id":"45ca2422","metadata":{"id":"45ca2422"},"source":["DataLoader 를 생성합니다\n"]},{"cell_type":"code","execution_count":null,"id":"a962c913","metadata":{"id":"a962c913"},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","\n","def collate_batch(batch, max_sequence_length):\n","    label_list, text_list = [], []\n","\n","    for text, label in batch:\n","        # 최대 문장길이를 넘어가는 단어는 제거합니다.\n","        processed_text = torch.tensor(text[:max_sequence_length], dtype=torch.int64) # 최대 길이를 넘어가면 슬라이싱\n","        text_list.append(processed_text)\n","        label_list.append(label)\n","\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","\n","    # padding을 주어 짧은 문장에 대한 길이를 맞춥니다.\n","    text_list = pad_sequence(text_list, batch_first=True, padding_value=0) # 패딩값을 줘서 부족한 길이는 채우기(맞추기)\n","\n","    return text_list.to(device), label_list.to(device)"]},{"cell_type":"code","execution_count":null,"id":"d2ad1c27","metadata":{"id":"d2ad1c27"},"outputs":[],"source":["# 한 문장에 최대 포함하는 단어의 개수를 지정합니다. (예시. 120 단어)\n","MAX_SEQUENCE_LENGTH = 120\n","\n","train_loader = DataLoader(\n","    train_ds,\n","    batch_size=32,\n","    shuffle=True,\n","    collate_fn=lambda x: collate_batch(x, MAX_SEQUENCE_LENGTH),\n",")\n","\n","validation_loader = DataLoader(\n","    valid_ds,\n","    batch_size=32,\n","    shuffle=False,\n","    collate_fn=lambda x: collate_batch(x, MAX_SEQUENCE_LENGTH),\n",")"]},{"cell_type":"code","execution_count":null,"id":"3ba69383","metadata":{"id":"3ba69383","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034580628,"user_tz":-540,"elapsed":2,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"5b867a61-1ebf-4e8f-e88b-9e72498d1d02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32, 18]), torch.Size([32]))"]},"metadata":{},"execution_count":38}],"source":["x, y = next(iter(train_loader))\n","x = x.to(device)\n","y = y.to(device)\n","\n","# x, y의 shape 확인\n","# (batch_size, seq_length), (batch_size)\n","x.shape, y.shape"]},{"cell_type":"code","execution_count":null,"id":"f708deff","metadata":{"id":"f708deff"},"outputs":[],"source":["# train_loader의 it\n","iterator = iter(train_loader)"]},{"cell_type":"code","execution_count":null,"id":"1b1d9bce","metadata":{"id":"1b1d9bce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034602813,"user_tz":-540,"elapsed":523,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"1e50ba5d-62de-42fb-a9e5-0adb9aa866f8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32, 21]), torch.Size([32]))"]},"metadata":{},"execution_count":43}],"source":["x, y = next(iterator)\n","x.shape, y.shape"]},{"cell_type":"code","execution_count":null,"id":"a3683d50","metadata":{"id":"a3683d50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034605601,"user_tz":-540,"elapsed":3,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"36fedfa9-c1b3-493d-efc0-a05b89cf5f37"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0,  3,  0, 19,  0,  0,  7,  0, 12,  0,  6,  9,  0,  3,  0,  0,  0,  0,\n","         0,  0,  0], device='cuda:0')"]},"metadata":{},"execution_count":44}],"source":["x[0]"]},{"cell_type":"code","execution_count":null,"id":"b83aa751","metadata":{"id":"b83aa751","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709034606742,"user_tz":-540,"elapsed":485,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"a692b85b-76cb-4897-9dcf-dfdb39e422ce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([191,   0, 129,   1,   0,   0,   1,   6,   0,   0,  32, 204,   1,  21,\n","         52,   2,   0, 644,   1,   5, 883], device='cuda:0')"]},"metadata":{},"execution_count":45}],"source":["x[2]"]},{"cell_type":"markdown","id":"b78fdb7b","metadata":{"id":"b78fdb7b"},"source":["## Embedding Layer\n"]},{"cell_type":"code","execution_count":null,"id":"b9b6981f","metadata":{"id":"b9b6981f"},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"id":"0728913d","metadata":{"id":"0728913d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709035290742,"user_tz":-540,"elapsed":7,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"f1cdb00d-ec26-4857-e77d-15a2e03eedf4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":47}],"source":["NUM_VOCAB = len(vocab)\n","NUM_VOCAB"]},{"cell_type":"code","execution_count":null,"id":"fefc0c68","metadata":{"id":"fefc0c68","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709035376697,"user_tz":-540,"elapsed":497,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"92ec8d93-948a-45ed-e395-ef81198915d8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32, 20]), torch.Size([32]))"]},"metadata":{},"execution_count":49}],"source":["x, y = next(iter(train_loader))\n","x = x.to(device)\n","y = y.to(device)\n","\n","x.shape, y.shape\n","# (batch_size, seq_length), (batch_size) 한 문장에 들어간 단어의 개수"]},{"cell_type":"markdown","id":"6795f862","metadata":{"id":"6795f862"},"source":["`nn.Embedding()` 생성\n"]},{"cell_type":"code","execution_count":null,"id":"e5b3c8b7","metadata":{"id":"e5b3c8b7"},"outputs":[],"source":["# Embedding: (vocab_size, embedding_dim)\n","EMBEDDING_DIM = 30  # Dimension을 30 차원으로 설정(hyper-parameter)\n","embedding = nn.Embedding(len(vocab), EMBEDDING_DIM).to(device)"]},{"cell_type":"markdown","id":"46254d79","metadata":{"id":"46254d79"},"source":["`nn.Embedding()` 의 입출력 shape 에 대한 이해\n"]},{"cell_type":"code","execution_count":null,"id":"96aae29f","metadata":{"id":"96aae29f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709035382113,"user_tz":-540,"elapsed":719,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"7aa93513-1cb7-4b58-b62f-ba248339083d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 20, 30])"]},"metadata":{},"execution_count":51}],"source":["# x : (batch_size, seq_length)\n","embedding_out = embedding(x)\n","embedding_out.shape\n","# embedding_out: (batch_size, seq_length, embedding_dim) 한 단어당 30차원이 추가(맵핑)"]},{"cell_type":"code","source":["embedding_out[0][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2U0Um5M1c9r5","executionInfo":{"status":"ok","timestamp":1709035496580,"user_tz":-540,"elapsed":3,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"eb359a66-1902-4594-e098-0eed9d4626a5"},"id":"2U0Um5M1c9r5","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.6517, -0.1083,  0.1789,  1.9432, -0.1924,  0.8609, -2.1043, -0.8672,\n","        -0.5252, -0.2743, -1.2242,  0.4111,  3.1094, -0.9358,  0.1438,  1.3130,\n","         1.8931, -0.2015,  1.1094, -0.9413, -1.8549,  0.4594, -0.6027, -1.7381,\n","        -0.6008,  1.4465,  0.4170, -1.2727, -0.5886,  2.0518], device='cuda:0',\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","id":"a12e26d0","metadata":{"id":"a12e26d0"},"source":["## LSTM Layer\n","\n","- 참고 링크: https://teddylee777.github.io/pytorch/pytorch-lstm/\n"]},{"cell_type":"code","execution_count":null,"id":"3ca56291","metadata":{"id":"3ca56291","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"ok","timestamp":1709036707241,"user_tz":-540,"elapsed":4,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"48542e4c-58ac-4de2-abfa-2f7f580deb1d"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://teddylee777.github.io/images/2023-03-05/lstm-shapes-01.png\" width=\"700\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":55}],"source":["from IPython.display import Image\n","\n","Image(url=\"https://teddylee777.github.io/images/2023-03-05/lstm-shapes-01.png\", width=700)"]},{"cell_type":"code","execution_count":null,"id":"0b4ff835","metadata":{"id":"0b4ff835","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037074470,"user_tz":-540,"elapsed":513,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"114a5bac-bb10-4019-c433-3651c211b8b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["BATCH_SIZE:  32\n","SEQ_LENGTH:  20\n"]}],"source":["EMBEDDING_DIM = 30  # input_size: embedding_dim(임베딩 차원)\n","HIDDEN_SIZE = 64  # hidden_size: 추출할 특성의 수(hyper-parameter)\n","NUM_LAYERS = 1  # LSTM Stacking Layer 수\n","BIDIRECTIONAL = 1  # 양방향 특성 추출: True(2), False(1)\n","\n","BATCH_SIZE = x.size(0)\n","SEQ_LENGTH = x.size(1)\n","print(\"BATCH_SIZE: \", BATCH_SIZE)\n","print(\"SEQ_LENGTH: \", SEQ_LENGTH)"]},{"cell_type":"code","execution_count":null,"id":"80244f22","metadata":{"id":"80244f22","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037076907,"user_tz":-540,"elapsed":1347,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"0084e150-8acd-4a0f-b096-b54c1041129d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM(30, 64, batch_first=True)"]},"metadata":{},"execution_count":57}],"source":["lstm = nn.LSTM(\n","    input_size=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE, batch_first=True, device=device\n",")\n","lstm"]},{"cell_type":"code","execution_count":null,"id":"f3fd738f","metadata":{"id":"f3fd738f"},"outputs":[],"source":["# initial weights 초기화(지금 들어가는 단어가 첫 단어다)\n","h_0 = torch.zeros(NUM_LAYERS * BIDIRECTIONAL, SEQ_LENGTH, HIDDEN_SIZE).to(device)\n","c_0 = torch.zeros(NUM_LAYERS * BIDIRECTIONAL, SEQ_LENGTH, HIDDEN_SIZE).to(device)"]},{"cell_type":"code","execution_count":null,"id":"bd517763","metadata":{"id":"bd517763","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037126028,"user_tz":-540,"elapsed":2,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"812f89b5-6c61-45d5-ea64-6414789ef64b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 20, 30])"]},"metadata":{},"execution_count":60}],"source":["embedding_out.shape"]},{"cell_type":"code","execution_count":null,"id":"2e0d4ffa","metadata":{"id":"2e0d4ffa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037130822,"user_tz":-540,"elapsed":3,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"b48f4822-3d89-456f-8e33-8358f2c5abce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 20, 64])"]},"metadata":{},"execution_count":61}],"source":["# 임베딩 레이어 Output, 초기화 (hidden_state, cell_state)\n","lstm_out, (hidden, cell) = lstm(embedding_out)\n","\n","# (batch_size, seq_length, hidden_size)\n","lstm_out.shape"]},{"cell_type":"code","execution_count":null,"id":"78c484ac","metadata":{"id":"78c484ac","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037134032,"user_tz":-540,"elapsed":621,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"8dfba5ed-55ba-454c-fd88-3c054c0b6dbd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 32, 64]), torch.Size([1, 32, 64]))"]},"metadata":{},"execution_count":62}],"source":["# (num_layers * bidirectional, batch_size, hidden_size)\n","# (num_layers * bidirectional, batch_size, hidden_size)\n","hidden.shape, cell.shape"]},{"cell_type":"markdown","id":"bf4782b8","metadata":{"id":"bf4782b8"},"source":["## Embedding -> LSTM 의 입출력 이해\n"]},{"cell_type":"code","execution_count":null,"id":"a993e649","metadata":{"id":"a993e649"},"outputs":[],"source":["def EmbeddingLSTM(\n","    x, vocab_size, embedding_dim, hidden_size, bidirectional, num_layers, device\n","):\n","    \"\"\"\n","    x             : 데이터 입력 (batch_size, seq_length)\n","    vocab_size    : 단어사전의 개수\n","    embedding_dim : 임베딩 차원\n","    hidden_size   : 특성추출의 개수(hyper-parameter)\n","    bidirectional : 양방향 특성 추출: 양방향(True), 단방향(False)\n","    num_layers    : Stacking LSTM 레이어 수, 기본: 1\n","    \"\"\"\n","    x = x.to(device)\n","    batch_size = x.size(0)\n","\n","    print(f\"===== Part1. 입력(x) =====\\n\")\n","    print(f\"입력(x)의 차원(batch_size({batch_size}), seq_length({x.size(1)}))\")\n","    print(f\"{x.shape}\\n\")\n","\n","    embedding = nn.Embedding(vocab_size, embedding_dim, device=device)\n","    embedding_out = embedding(x)\n","    print(f\"===== Part2. Embedding =====\\n\")\n","    print(\n","        f\"(batch_size({batch_size}), seq_length({x.size(1)}), embedding_dim({embedding_dim}))\"\n","    )\n","    print(f\"{embedding_out.shape}\")\n","\n","    lstm = nn.LSTM(\n","        input_size=embedding_dim,\n","        hidden_size=hidden_size,\n","        num_layers=num_layers,\n","        bidirectional=bidirectional,\n","        batch_first=True,\n","        device=device,\n","    )\n","\n","    bidi = 2 if bidirectional else 1\n","\n","    out, (h, c) = lstm(embedding_out)\n","    print()\n","    print(f\"===== Part3. LSTM =====\\n\")\n","    print(\"out, (h, c) = lstm(x)\\n\")\n","    print(\"LSTM output\")\n","    print(\n","        f\"(batch_size({x.size(0)}), seq_length({x.size(1)}), hidden_size({hidden_size})*bidirectional({bidi}))\"\n","    )\n","    print(f\"{out.shape}\\n\")\n","    print(\"===\" * 8)\n","    print(\"\\n(hidden, cell) state\\n\")\n","    print(\n","        f\"(num_layers({num_layers})*bidirectional({bidi}), batch_size({batch_size}), hidden_size({hidden_size}))\"\n","    )\n","    print(f\"{h.shape}\\n\")\n","    print(\"===\" * 8)"]},{"cell_type":"code","execution_count":null,"id":"ed6a2b32","metadata":{"id":"ed6a2b32","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037171623,"user_tz":-540,"elapsed":628,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"ee2b8041-1ca9-4be9-92dc-fb55aaf8ba50"},"outputs":[{"output_type":"stream","name":"stdout","text":["===== Part1. 입력(x) =====\n","\n","입력(x)의 차원(batch_size(32), seq_length(20))\n","torch.Size([32, 20])\n","\n","===== Part2. Embedding =====\n","\n","(batch_size(32), seq_length(20), embedding_dim(30))\n","torch.Size([32, 20, 30])\n","\n","===== Part3. LSTM =====\n","\n","out, (h, c) = lstm(x)\n","\n","LSTM output\n","(batch_size(32), seq_length(20), hidden_size(64)*bidirectional(1))\n","torch.Size([32, 20, 64])\n","\n","========================\n","\n","(hidden, cell) state\n","\n","(num_layers(2)*bidirectional(1), batch_size(32), hidden_size(64))\n","torch.Size([2, 32, 64])\n","\n","========================\n"]}],"source":["EmbeddingLSTM(\n","    x,\n","    vocab_size=len(vocab),\n","    embedding_dim=30,\n","    hidden_size=64,\n","    bidirectional=False,\n","    num_layers=2,\n","    device=device,\n",")"]},{"cell_type":"markdown","id":"feb7219c","metadata":{"id":"feb7219c"},"source":["## 모델\n"]},{"cell_type":"code","execution_count":null,"id":"f8f2d79f","metadata":{"id":"f8f2d79f"},"outputs":[],"source":["from tqdm import tqdm  # Progress Bar 출력\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","class TextClassificationModel(nn.Module):\n","    def __init__(\n","        self,\n","        num_classes,\n","        vocab_size,\n","        embedding_dim,\n","        hidden_size,\n","        num_layers,\n","        bidirectional=True,\n","        drop_prob=0.1,\n","    ):\n","        super(TextClassificationModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bidirectional = 2 if bidirectional else 1\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size, embedding_dim=embedding_dim\n","        )\n","\n","        self.lstm = nn.LSTM(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            bidirectional=bidirectional,\n","        )\n","\n","        self.dropout = nn.Dropout(drop_prob)\n","\n","        self.relu = nn.ReLU()\n","\n","        self.fc = nn.Linear(hidden_size * self.bidirectional, hidden_size)\n","        self.output = nn.Linear(hidden_size, num_classes)\n","\n","    def init_hidden_and_cell_state(self, batch_size, device):\n","        # LSTM 입력시 초기 Cell 에 대한 가중치 초기화를 진행합니다.\n","        # (num_layers*bidirectional, batch_size, hidden_size)\n","        self.hidden_and_cell = (\n","            torch.zeros(\n","                self.num_layers * self.bidirectional, batch_size, self.hidden_size\n","            ).to(device),\n","            torch.zeros(\n","                self.num_layers * self.bidirectional, batch_size, self.hidden_size\n","            ).to(device),\n","        )\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        output, (h, c) = self.lstm(x, self.hidden_and_cell)\n","        # (batch_size, seq_length, hidden_size*bidirectional)\n","        # last sequence 의 (batch_size, hidden_size*bidirectional)\n","        h = output[:, -1, :] # 아웃풋의 마지막 cell의 값. 마지막 셀의 출력값만 가져온 것(히든이나 셀을 쓸 수도 있다.)\n","        o = self.dropout(h)\n","        o = self.relu(self.fc(o))\n","        o = self.dropout(o)\n","        return self.output(o)"]},{"cell_type":"code","execution_count":null,"id":"278f6bfb","metadata":{"id":"278f6bfb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037472144,"user_tz":-540,"elapsed":670,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"3f1e6dfb-7814-4461-bdaa-570d7700488e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TextClassificationModel(\n","  (embedding): Embedding(1000, 16)\n","  (lstm): LSTM(16, 32, num_layers=2, batch_first=True, bidirectional=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (relu): ReLU()\n","  (fc): Linear(in_features=64, out_features=32, bias=True)\n","  (output): Linear(in_features=32, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":66}],"source":["config = {\n","    \"num_classes\": 2,\n","    \"vocab_size\": len(vocab),\n","    \"embedding_dim\": 16,\n","    \"hidden_size\": 32,\n","    \"num_layers\": 2,\n","    \"bidirectional\": True,\n","}\n","\n","model = TextClassificationModel(**config)\n","model.to(device)"]},{"cell_type":"markdown","id":"3c61947b","metadata":{"id":"3c61947b"},"source":["## 손실 함수 및 옵티마이저 정의\n"]},{"cell_type":"code","execution_count":null,"id":"030efd23","metadata":{"id":"030efd23"},"outputs":[],"source":["# loss 정의: CrossEntropyLoss\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"id":"19edb2a6","metadata":{"id":"19edb2a6"},"outputs":[],"source":["from tqdm import tqdm\n","\n","\n","def fit(model, data_loader, loss_fn, optimizer, device, phase=\"train\"):\n","    if phase == \"train\":\n","        # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n","        model.train()\n","    else:\n","        # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n","        model.eval()\n","\n","    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n","    running_loss = 0\n","    corr = 0\n","\n","    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n","    prograss_bar = tqdm(\n","        data_loader, leave=False, unit=\"batch\", total=len(data_loader), mininterval=1\n","    )\n","\n","    # mini-batch 학습을 시작합니다.\n","    for txt, lbl in prograss_bar:\n","        # image, label 데이터를 device에 올립니다.\n","        txt, lbl = txt.to(device), lbl.to(device)\n","\n","        optimizer.zero_grad()\n","        # 누적 Gradient를 초기화 합니다. 반드시 필요!\n","        with torch.set_grad_enabled(phase == \"train\"):\n","            model.init_hidden_and_cell_state(len(txt), device)\n","            # Forward Propagation을 진행하여 결과를 얻습니다.\n","            output = model(txt)\n","\n","            # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n","            loss = loss_fn(output, lbl)\n","\n","            if phase == \"train\":\n","                # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n","                loss.backward()\n","\n","                # 계산된 Gradient를 업데이트 합니다.\n","                optimizer.step()\n","\n","        # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n","        pred = output.argmax(axis=1)\n","\n","        # 정답 개수를 카운트 합니다.\n","        corr += (lbl == pred).sum().item()\n","\n","        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n","        running_loss += loss.item()\n","\n","    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n","    acc = corr / len(data_loader.dataset)\n","\n","    # 평균 손실(loss)과 정확도를 반환합니다.\n","    # train_loss, train_acc\n","    return running_loss / len(data_loader), acc"]},{"cell_type":"code","execution_count":null,"id":"6de61bd7","metadata":{"id":"6de61bd7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037552148,"user_tz":-540,"elapsed":22582,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"5655fe49-56bc-4216-cd02-54f4e6a3f9cf"},"outputs":[{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["[INFO] val_loss has been improved from inf to 0.58071. Saving Model!\n","[Epoch01] time: 0m 5s \t loss: 0.66644, acc: 0.59250 | val_loss: 0.58071, val_acc: 0.69787\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["[INFO] val_loss has been improved from 0.58071 to 0.48387. Saving Model!\n","[Epoch02] time: 0m 4s \t loss: 0.52523, acc: 0.73993 | val_loss: 0.48387, val_acc: 0.76844\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["[INFO] val_loss has been improved from 0.48387 to 0.44555. Saving Model!\n","[Epoch03] time: 0m 5s \t loss: 0.45286, acc: 0.79192 | val_loss: 0.44555, val_acc: 0.79240\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["[INFO] val_loss has been improved from 0.44555 to 0.42525. Saving Model!\n","[Epoch04] time: 0m 4s \t loss: 0.40831, acc: 0.81556 | val_loss: 0.42525, val_acc: 0.80101\n"]},{"output_type":"stream","name":"stderr","text":["                                          "]},{"output_type":"stream","name":"stdout","text":["[Epoch05] time: 0m 4s \t loss: 0.37758, acc: 0.83124 | val_loss: 0.42685, val_acc: 0.81299\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["import time\n","\n","# 최대 Epoch을 지정합니다.\n","num_epochs = 5\n","\n","min_loss = np.inf\n","\n","STATE_DICT_PATH = \"LSTM-Text-Classification.pth\"\n","\n","# Epoch 별 훈련 및 검증을 수행합니다.\n","for epoch in range(num_epochs):\n","    # Model Training\n","    # 훈련 손실과 정확도를 반환 받습니다.\n","    start = time.time()\n","    train_loss, train_acc = fit(\n","        model, train_loader, loss_fn, optimizer, device, phase=\"train\"\n","    )\n","\n","    # 검증 손실과 검증 정확도를 반환 받습니다.\n","    val_loss, val_acc = fit(\n","        model, validation_loader, loss_fn, optimizer, device, phase=\"eval\"\n","    )\n","\n","    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n","    if val_loss < min_loss:\n","        print(\n","            f\"[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!\"\n","        )\n","        min_loss = val_loss\n","        torch.save(model.state_dict(), STATE_DICT_PATH)\n","\n","    time_elapsed = time.time() - start\n","    # Epoch 별 결과를 출력합니다.\n","    print(\n","        f\"[Epoch{epoch+1:02d}] time: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s \\t loss: {train_loss:.5f}, acc: {train_acc:.5f} | val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}\"\n","    )"]},{"cell_type":"markdown","id":"c922511c","metadata":{"id":"c922511c"},"source":["## 저장한 가중치 로드\n"]},{"cell_type":"code","execution_count":null,"id":"0c8e549a","metadata":{"id":"0c8e549a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037601641,"user_tz":-540,"elapsed":520,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"6745540a-8a25-42df-9c01-424d508bc4b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":70}],"source":["# 모델에 저장한 가중치를 로드합니다.\n","model.load_state_dict(torch.load(STATE_DICT_PATH))"]},{"cell_type":"markdown","id":"d803ce5b","metadata":{"id":"d803ce5b"},"source":["## 최종 검증성능 측정\n"]},{"cell_type":"code","execution_count":null,"id":"346c77f4","metadata":{"id":"346c77f4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709037603085,"user_tz":-540,"elapsed":525,"user":{"displayName":"김요엘","userId":"12082156853815649703"}},"outputId":"d373e5e3-2b77-4be0-f328-2297ce4a46de"},"outputs":[{"output_type":"stream","name":"stderr","text":["                                          "]},{"output_type":"stream","name":"stdout","text":["\n","evaluation loss: 0.42525, evaluation accuracy: 0.80101\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["# 최종 검증 손실(validation loss)와 검증 정확도(validation accuracy)를 산출합니다.\n","final_loss, final_acc = fit(\n","    model, validation_loader, loss_fn, optimizer, device, phase=\"eval\"\n",")\n","print(f\"\\nevaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}\")"]},{"cell_type":"code","execution_count":null,"id":"672b63be","metadata":{"id":"672b63be"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[{"file_id":"https://github.com/teddylee777/pytorch-tutorial/blob/main/16-nlp-tokenizer-embedding-lstm.ipynb","timestamp":1709033372272}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}