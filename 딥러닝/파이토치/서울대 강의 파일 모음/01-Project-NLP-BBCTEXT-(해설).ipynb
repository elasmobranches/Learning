{"cells":[{"cell_type":"markdown","id":"2bb5885e","metadata":{"id":"2bb5885e"},"source":["## 환경설정\n","\n","1. http://braincrew2.iptime.org:8001 에 접속하여 회원가입해 주세요. (비밀번호는 단순하게 기입하시는 것을 권장 드려요. 예. 1234)\n","2. `username` 에 이메일 형식의 아이디를 기입해 주세요.\n","3. `password` 에 비밀번호를 기입해 주세요.\n"]},{"cell_type":"code","execution_count":null,"id":"f3c39526","metadata":{"id":"f3c39526"},"outputs":[],"source":["project = \"BBCTEXT\"  # 수정하지 마세요\n","username = \"\"  # 이메일아이디 (예시. abc@hello.com)\n","password = \"\"  # 비밀번호"]},{"cell_type":"markdown","id":"744dbbce","metadata":{"id":"744dbbce"},"source":["아래의 코드를 순서대로 실행해 주세요.\n"]},{"cell_type":"code","execution_count":null,"id":"e1ecbacf","metadata":{"id":"e1ecbacf"},"outputs":[],"source":["import os\n","import requests\n","\n","if not os.path.exists(\"competition.py\"):\n","    url = \"https://link.teddynote.com/COMPT\"\n","    file_name = \"competition.py\"\n","    response = requests.get(url)\n","    with open(file_name, \"wb\") as file:\n","        file.write(response.content)"]},{"cell_type":"code","execution_count":null,"id":"3df2a81d","metadata":{"id":"3df2a81d","outputId":"68006e75-e3ff-49d1-d98c-0cc1ca6b9f5d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.80M/1.80M [00:00<00:00, 21.7MiB/s]\n"]}],"source":["import competition\n","\n","# 파일 다운로드\n","competition.download_competition_files(\n","    f\"https://link.teddynote.com/{project}\", use_competition_url=False\n",")"]},{"cell_type":"markdown","id":"a95ce279","metadata":{"id":"a95ce279"},"source":["## 데이터 로드\n"]},{"cell_type":"code","execution_count":null,"id":"0e335ef3","metadata":{"id":"0e335ef3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","import os\n","\n","# Data 경로 설정\n","DATA_DIR = \"data\"\n","\n","# 경고 무시\n","warnings.filterwarnings(\"ignore\")\n","\n","SEED = 123\n","\n","train = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n","test = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))"]},{"cell_type":"code","execution_count":null,"id":"af2d404b","metadata":{"id":"af2d404b","outputId":"9846eade-bfd4-4997-c876-f553518af34c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>officials respond in court row australian tenn...</td>\n","      <td>sport</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>slow start to speedy net services faster broad...</td>\n","      <td>tech</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>amnesty chief laments war failure the lack of ...</td>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dal maso in to replace bergamasco david dal ma...</td>\n","      <td>sport</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>technology gets the creative bug the hi-tech a...</td>\n","      <td>tech</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             content     label\n","0  officials respond in court row australian tenn...     sport\n","1  slow start to speedy net services faster broad...      tech\n","2  amnesty chief laments war failure the lack of ...  politics\n","3  dal maso in to replace bergamasco david dal ma...     sport\n","4  technology gets the creative bug the hi-tech a...      tech"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# train 데이터셋 확인\n","train.head()"]},{"cell_type":"code","execution_count":null,"id":"c22393c6","metadata":{"id":"c22393c6","outputId":"18c7d13c-83e8-45dc-9f54-42ae92945992"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>child access laws shake-up parents who refuse ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fry set for role in hitchhiker s actor stephen...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>palestinian economy in decline despite a short...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>japanese banking battle at an end japan s sumi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>manufacturing recovery  slowing  uk manufactur...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             content\n","0  child access laws shake-up parents who refuse ...\n","1  fry set for role in hitchhiker s actor stephen...\n","2  palestinian economy in decline despite a short...\n","3  japanese banking battle at an end japan s sumi...\n","4  manufacturing recovery  slowing  uk manufactur..."]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# test 데이터셋 확인\n","test.head()"]},{"cell_type":"markdown","id":"879d2859","metadata":{"id":"879d2859"},"source":["## 토큰화 (Word Tokenization)\n","\n","- get_tokenizer로 토크나이저 생성\n","- `basic_english`, `spacy`, `revtok`, `subword` 등 지정이 가능하나, 몇몇 토크나이저는 추가 라이브러리 설치가 필요합니다.\n"]},{"cell_type":"code","execution_count":null,"id":"3925477a","metadata":{"id":"3925477a"},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","\n","# 토큰 생성\n","tokenizer = get_tokenizer(\"basic_english\")"]},{"cell_type":"markdown","id":"33d8f542","metadata":{"id":"33d8f542"},"source":["## 단어사전 생성\n"]},{"cell_type":"code","execution_count":null,"id":"fae2553f","metadata":{"id":"fae2553f"},"outputs":[],"source":["from torchtext.vocab import build_vocab_from_iterator\n","\n","\n","def yield_tokens(sentences):\n","    for text in sentences:\n","        yield tokenizer(text)"]},{"cell_type":"markdown","id":"29176448","metadata":{"id":"29176448"},"source":["`build_vocab_from_iterator` 를 활용하여 단어 사전을 생성합니다.\n","\n","- `min_freq`: 최소 빈도의 토큰의 개수를 입력합니다.\n","- `max_tokens`: 최대 빈도 토큰의 수를 한정합니다. 빈도수 기준으로 산정합니다.\n"]},{"cell_type":"code","execution_count":null,"id":"71928f6c","metadata":{"id":"71928f6c"},"outputs":[],"source":["vocab = build_vocab_from_iterator(\n","    yield_tokens(train[\"content\"].tolist()),  # 텍스트 Iterator\n","    # 스페셜 토큰\n","    specials=[\"<UNK>\"],\n","    min_freq=2,  # 최소 빈도 토큰\n","    max_tokens=1000,  # 최대 토큰 개수\n",")\n","\n","vocab.set_default_index(vocab[\"<UNK>\"])"]},{"cell_type":"markdown","id":"0ade2e3e","metadata":{"id":"0ade2e3e"},"source":["## 단어사전의 개수 출력\n"]},{"cell_type":"code","execution_count":null,"id":"75bb7cb3","metadata":{"id":"75bb7cb3","outputId":"eba9ced5-9c4a-4ff5-b23c-2f61cf89a94a"},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# 전체 단어사전의 개수 출력\n","len(vocab)"]},{"cell_type":"markdown","id":"3a17a169","metadata":{"id":"3a17a169"},"source":["## 라벨 맵 생성 (문자 -> 숫자 변환)\n"]},{"cell_type":"code","execution_count":null,"id":"27fe3aab","metadata":{"id":"27fe3aab","outputId":"61c9b868-e982-4005-e801-46b3255f71e8"},"outputs":[{"data":{"text/plain":["{'business': 0, 'sport': 1, 'politics': 2, 'tech': 3, 'entertainment': 4}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# label 맵과 idx_to_label 생성\n","label_map = {v: i for i, v in enumerate(train[\"label\"].value_counts().keys())}\n","idx_to_label = {idx: lbl for lbl, idx in label_map.items()}"]},{"cell_type":"code","execution_count":null,"id":"eea63497","metadata":{"id":"eea63497"},"outputs":[],"source":["train[\"label_num\"] = train[\"label\"].map(label_map)"]},{"cell_type":"markdown","id":"263a9cc8","metadata":{"id":"263a9cc8"},"source":["## Dataset 분할\n"]},{"cell_type":"code","execution_count":null,"id":"9db988dd","metadata":{"id":"9db988dd"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(\n","    train[\"content\"], train[\"label_num\"], test_size=0.2, random_state=SEED\n",")"]},{"cell_type":"markdown","id":"02d38128","metadata":{"id":"02d38128"},"source":["## Dataset 생성\n"]},{"cell_type":"code","execution_count":null,"id":"b0bff8f3","metadata":{"id":"b0bff8f3"},"outputs":[],"source":["from torch.utils.data import DataLoader, Dataset\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, texts, labels, vocab, tokenizer, is_train=True):\n","        super().__init__()\n","        self.texts = texts\n","        self.is_train = is_train\n","        if is_train:\n","            self.labels = labels\n","        self.vocab = vocab\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts.iloc[idx]\n","        if self.is_train:\n","            label = self.labels.iloc[idx]\n","            return self.vocab(self.tokenizer(text)), label\n","        else:\n","            return self.vocab(self.tokenizer(text))"]},{"cell_type":"code","execution_count":null,"id":"9d3251b1","metadata":{"id":"9d3251b1"},"outputs":[],"source":["# Custom Dataset 생성\n","train_ds = CustomDataset(x_train, y_train, vocab=vocab, tokenizer=tokenizer)\n","valid_ds = CustomDataset(x_test, y_test, vocab=vocab, tokenizer=tokenizer)\n","test_ds = CustomDataset(\n","    test[\"content\"], None, vocab=vocab, tokenizer=tokenizer, is_train=False\n",")"]},{"cell_type":"code","execution_count":null,"id":"0f6973b9","metadata":{"id":"0f6973b9","outputId":"bdffe01e-e4a9-4200-90ef-8d1899809e37"},"outputs":[{"data":{"text/plain":["(281, 0)"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["# 1개의 데이터 추출\n","text, label = next(iter(train_ds))\n","len(text), label"]},{"cell_type":"markdown","id":"1f2a56d3","metadata":{"id":"1f2a56d3"},"source":["## DataLoader 생성\n"]},{"cell_type":"code","execution_count":null,"id":"ed101327","metadata":{"id":"ed101327","outputId":"f475b7ea-9870-4151-94c1-4ef962a33028"},"outputs":[{"name":"stdout","output_type":"stream","text":["mps\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# CUDA 사용 가능 여부 확인\n","if torch.backends.mps.is_built():\n","    # mac os mps 지원 체크\n","    device = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n","else:\n","    # cuda 사용 가능한지 체크\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"id":"881230a7","metadata":{"id":"881230a7"},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","\n","def collate_batch(batch, max_sequence_length, is_train=True):\n","    if is_train:\n","        label_list, text_list = [], []\n","\n","        for text, label in batch:\n","            # 최대 문장길이를 넘어가는 단어는 제거합니다.\n","            processed_text = torch.tensor(text[:max_sequence_length], dtype=torch.int64)\n","            text_list.append(processed_text)\n","            label_list.append(label)\n","\n","        label_list = torch.tensor(label_list, dtype=torch.int64)\n","\n","        # padding을 주어 짧은 문장에 대한 길이를 맞춥니다.\n","        text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n","\n","        return text_list.to(device), label_list.to(device)\n","\n","    else:\n","        text_list = []\n","\n","        for text in batch:\n","            # 최대 문장길이를 넘어가는 단어는 제거합니다.\n","            processed_text = torch.tensor(text[:max_sequence_length], dtype=torch.int64)\n","            text_list.append(processed_text)\n","\n","        # padding을 주어 짧은 문장에 대한 길이를 맞춥니다.\n","        text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n","\n","        return text_list.to(device)"]},{"cell_type":"code","execution_count":null,"id":"d2ad1c27","metadata":{"id":"d2ad1c27"},"outputs":[],"source":["# 한 문장에 최대 포함하는 단어의 개수를 지정합니다. (예시. 120 단어)\n","MAX_SEQUENCE_LENGTH = 120\n","\n","train_loader = DataLoader(\n","    train_ds,\n","    batch_size=32,\n","    shuffle=True,\n","    collate_fn=lambda x: collate_batch(x, MAX_SEQUENCE_LENGTH),\n",")\n","\n","validation_loader = DataLoader(\n","    valid_ds,\n","    batch_size=32,\n","    shuffle=False,\n","    collate_fn=lambda x: collate_batch(x, MAX_SEQUENCE_LENGTH),\n",")\n","\n","test_loader = DataLoader(\n","    test_ds,\n","    batch_size=1,\n","    shuffle=False,\n","    collate_fn=lambda x: collate_batch(x, MAX_SEQUENCE_LENGTH, is_train=False),\n",")"]},{"cell_type":"code","execution_count":null,"id":"299b1bfc","metadata":{"id":"299b1bfc","outputId":"8ff51283-0cb5-46bf-af68-68c4fd494ae9"},"outputs":[{"data":{"text/plain":["(torch.Size([32, 120]), torch.Size([32]))"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["x, y = next(iter(train_loader))\n","x = x.to(device)\n","y = y.to(device)\n","\n","# x, y의 shape 확인\n","# (batch_size, seq_length), (batch_size)\n","x.shape, y.shape"]},{"cell_type":"markdown","id":"8e4112ba","metadata":{"id":"8e4112ba"},"source":["## 모델\n"]},{"cell_type":"code","execution_count":null,"id":"f8f2d79f","metadata":{"id":"f8f2d79f"},"outputs":[],"source":["from tqdm import tqdm  # Progress Bar 출력\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","class TextClassificationModel(nn.Module):\n","    def __init__(\n","        self,\n","        num_classes,\n","        vocab_size,\n","        embedding_dim,\n","        hidden_size,\n","        num_layers,\n","        bidirectional=True,\n","        drop_prob=0.1,\n","    ):\n","        super(TextClassificationModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bidirectional = 2 if bidirectional else 1\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocab_size, embedding_dim=embedding_dim\n","        )\n","\n","        self.lstm = nn.LSTM(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            bidirectional=bidirectional,\n","        )\n","\n","        self.dropout = nn.Dropout(drop_prob)\n","\n","        self.relu = nn.ReLU()\n","\n","        self.fc = nn.Linear(hidden_size * self.bidirectional, hidden_size)\n","        self.output = nn.Linear(hidden_size, num_classes)\n","\n","    def init_hidden_and_cell_state(self, batch_size, device):\n","        # LSTM 입력시 초기 Cell 에 대한 가중치 초기화를 진행합니다.\n","        # (num_layers*bidirectional, batch_size, hidden_size)\n","        self.hidden_and_cell = (\n","            torch.zeros(\n","                self.num_layers * self.bidirectional, batch_size, self.hidden_size\n","            ).to(device),\n","            torch.zeros(\n","                self.num_layers * self.bidirectional, batch_size, self.hidden_size\n","            ).to(device),\n","        )\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        output, (h, c) = self.lstm(x, self.hidden_and_cell)\n","        # (batch_size, seq_length, hidden_size*bidirectional)\n","        # last sequence 의 (batch_size, hidden_size*bidirectional)\n","        h = output[:, -1, :]\n","        o = self.dropout(h)\n","        o = self.relu(self.fc(o))\n","        o = self.dropout(o)\n","        return self.output(o)"]},{"cell_type":"markdown","id":"fe7a2fa0","metadata":{"id":"fe7a2fa0"},"source":["## 모델 생성\n"]},{"cell_type":"code","execution_count":null,"id":"278f6bfb","metadata":{"id":"278f6bfb","outputId":"673d7039-3ee0-40c4-c764-d8a76e185aec"},"outputs":[{"data":{"text/plain":["TextClassificationModel(\n","  (embedding): Embedding(1000, 30)\n","  (lstm): LSTM(30, 32, num_layers=2, batch_first=True, bidirectional=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (relu): ReLU()\n","  (fc): Linear(in_features=64, out_features=32, bias=True)\n","  (output): Linear(in_features=32, out_features=5, bias=True)\n",")"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["config = {\n","    \"num_classes\": 5,\n","    \"vocab_size\": len(vocab),\n","    \"embedding_dim\": 30,\n","    \"hidden_size\": 32,\n","    \"num_layers\": 2,\n","    \"bidirectional\": True,\n","}\n","\n","model = TextClassificationModel(**config)\n","model.to(device)"]},{"cell_type":"markdown","id":"f4816050","metadata":{"id":"f4816050"},"source":["## 손실함수 및 옵티마이저 정의\n"]},{"cell_type":"code","execution_count":null,"id":"030efd23","metadata":{"id":"030efd23"},"outputs":[],"source":["# loss 정의: CrossEntropyLoss\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n","optimizer = optim.Adam(model.parameters(), lr=0.05)"]},{"cell_type":"code","execution_count":null,"id":"6f3fae59","metadata":{"id":"6f3fae59"},"outputs":[],"source":["from tqdm import tqdm\n","\n","\n","def fit(model, data_loader, loss_fn, optimizer, device, phase=\"train\"):\n","    if phase == \"train\":\n","        # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n","        model.train()\n","    else:\n","        # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n","        model.eval()\n","\n","    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n","    running_loss = 0\n","    corr = 0\n","\n","    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n","    prograss_bar = tqdm(\n","        data_loader, leave=False, unit=\"batch\", total=len(data_loader), mininterval=1\n","    )\n","\n","    # mini-batch 학습을 시작합니다.\n","    for txt, lbl in prograss_bar:\n","        # image, label 데이터를 device에 올립니다.\n","        txt, lbl = txt.to(device), lbl.to(device)\n","\n","        optimizer.zero_grad()\n","        # 누적 Gradient를 초기화 합니다.\n","        with torch.set_grad_enabled(phase == \"train\"):\n","            model.init_hidden_and_cell_state(len(txt), device)\n","            # Forward Propagation을 진행하여 결과를 얻습니다.\n","            output = model(txt)\n","\n","            # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n","            loss = loss_fn(output, lbl)\n","\n","            if phase == \"train\":\n","                # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n","                loss.backward()\n","\n","                # 계산된 Gradient를 업데이트 합니다.\n","                optimizer.step()\n","\n","        # output 의 뉴런별 확률 값을 sparse vector 로 변환합니다.\n","        pred = output.argmax(axis=1)\n","\n","        # 정답 개수를 카운트 합니다.\n","        corr += (lbl == pred).sum().item()\n","\n","        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n","        running_loss += loss.item()\n","\n","    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n","    acc = corr / len(data_loader.dataset)\n","\n","    # 평균 손실(loss)과 정확도를 반환합니다.\n","    # train_loss, train_acc\n","    return running_loss / len(data_loader), acc"]},{"cell_type":"code","execution_count":null,"id":"49b8dab3","metadata":{"id":"49b8dab3","outputId":"9d93e3f9-9496-42d6-ae3b-b73d19ebb5f7"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from inf to 1.54804. Saving Model!\n","[Epoch01] time: 0m 1s \t loss: 1.73921, acc: 0.25351 | val_loss: 1.54804, val_acc: 0.32584\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.54804 to 1.33906. Saving Model!\n","[Epoch02] time: 0m 1s \t loss: 1.45371, acc: 0.33708 | val_loss: 1.33906, val_acc: 0.35112\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.33906 to 1.31649. Saving Model!\n","[Epoch03] time: 0m 1s \t loss: 1.35062, acc: 0.38062 | val_loss: 1.31649, val_acc: 0.43820\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.31649 to 1.16235. Saving Model!\n","[Epoch04] time: 0m 1s \t loss: 1.22537, acc: 0.38834 | val_loss: 1.16235, val_acc: 0.42697\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch05] time: 0m 1s \t loss: 1.13782, acc: 0.45646 | val_loss: 1.20286, val_acc: 0.46629\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch06] time: 0m 1s \t loss: 1.10192, acc: 0.47472 | val_loss: 1.16629, val_acc: 0.49438\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.16235 to 1.14814. Saving Model!\n","[Epoch07] time: 0m 1s \t loss: 1.03616, acc: 0.49228 | val_loss: 1.14814, val_acc: 0.54213\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch08] time: 0m 1s \t loss: 1.02745, acc: 0.49228 | val_loss: 1.28084, val_acc: 0.51685\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.14814 to 1.14598. Saving Model!\n","[Epoch09] time: 0m 1s \t loss: 0.97822, acc: 0.53792 | val_loss: 1.14598, val_acc: 0.46067\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch10] time: 0m 1s \t loss: 0.94439, acc: 0.54565 | val_loss: 1.26801, val_acc: 0.55337\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.14598 to 1.14480. Saving Model!\n","[Epoch11] time: 0m 1s \t loss: 0.97128, acc: 0.53371 | val_loss: 1.14480, val_acc: 0.47472\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch12] time: 0m 1s \t loss: 1.02625, acc: 0.54143 | val_loss: 1.18371, val_acc: 0.50000\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch13] time: 0m 1s \t loss: 1.03783, acc: 0.54775 | val_loss: 1.18875, val_acc: 0.42135\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.14480 to 1.12214. Saving Model!\n","[Epoch14] time: 0m 1s \t loss: 1.16165, acc: 0.48244 | val_loss: 1.12214, val_acc: 0.51124\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch15] time: 0m 1s \t loss: 1.15152, acc: 0.48666 | val_loss: 1.25575, val_acc: 0.49438\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.12214 to 1.10257. Saving Model!\n","[Epoch16] time: 0m 1s \t loss: 1.08030, acc: 0.51124 | val_loss: 1.10257, val_acc: 0.54775\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch17] time: 0m 1s \t loss: 1.00182, acc: 0.55337 | val_loss: 1.27186, val_acc: 0.52528\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch18] time: 0m 1s \t loss: 1.03513, acc: 0.55758 | val_loss: 1.12043, val_acc: 0.60112\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch19] time: 0m 1s \t loss: 0.98195, acc: 0.58708 | val_loss: 1.22516, val_acc: 0.51404\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch20] time: 0m 1s \t loss: 1.01532, acc: 0.58778 | val_loss: 1.29248, val_acc: 0.47472\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch21] time: 0m 1s \t loss: 1.01088, acc: 0.56039 | val_loss: 1.28032, val_acc: 0.45225\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch22] time: 0m 1s \t loss: 1.05665, acc: 0.56671 | val_loss: 1.29050, val_acc: 0.48596\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch23] time: 0m 1s \t loss: 0.99098, acc: 0.56882 | val_loss: 1.24929, val_acc: 0.48876\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch24] time: 0m 1s \t loss: 0.95418, acc: 0.58778 | val_loss: 1.14880, val_acc: 0.57584\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch25] time: 0m 1s \t loss: 1.04862, acc: 0.54705 | val_loss: 1.30636, val_acc: 0.48596\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch26] time: 0m 1s \t loss: 1.12018, acc: 0.51615 | val_loss: 1.22341, val_acc: 0.48315\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.10257 to 1.10242. Saving Model!\n","[Epoch27] time: 0m 1s \t loss: 1.08787, acc: 0.53160 | val_loss: 1.10242, val_acc: 0.53090\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[INFO] val_loss has been improved from 1.10242 to 0.99721. Saving Model!\n","[Epoch28] time: 0m 1s \t loss: 1.00024, acc: 0.57514 | val_loss: 0.99721, val_acc: 0.56742\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch29] time: 0m 1s \t loss: 0.93144, acc: 0.58638 | val_loss: 1.08381, val_acc: 0.55337\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch30] time: 0m 1s \t loss: 0.87436, acc: 0.62360 | val_loss: 1.00890, val_acc: 0.57022\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch31] time: 0m 1s \t loss: 0.90116, acc: 0.62640 | val_loss: 1.08643, val_acc: 0.58146\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch32] time: 0m 1s \t loss: 0.87248, acc: 0.62219 | val_loss: 1.07115, val_acc: 0.50000\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch33] time: 0m 1s \t loss: 0.92714, acc: 0.59691 | val_loss: 1.10900, val_acc: 0.49438\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch34] time: 0m 1s \t loss: 0.88691, acc: 0.60885 | val_loss: 1.20281, val_acc: 0.53371\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch35] time: 0m 1s \t loss: 0.96899, acc: 0.57303 | val_loss: 1.17705, val_acc: 0.53371\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch36] time: 0m 1s \t loss: 0.94896, acc: 0.59270 | val_loss: 1.15528, val_acc: 0.50000\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch37] time: 0m 1s \t loss: 0.97770, acc: 0.57444 | val_loss: 1.22656, val_acc: 0.51404\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch38] time: 0m 1s \t loss: 0.98075, acc: 0.57935 | val_loss: 1.09690, val_acc: 0.60955\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch39] time: 0m 1s \t loss: 0.93542, acc: 0.60042 | val_loss: 1.21284, val_acc: 0.58989\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch40] time: 0m 1s \t loss: 1.00675, acc: 0.56882 | val_loss: 1.13800, val_acc: 0.60393\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch41] time: 0m 1s \t loss: 0.93146, acc: 0.59691 | val_loss: 1.22316, val_acc: 0.40169\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch42] time: 0m 1s \t loss: 0.96894, acc: 0.57584 | val_loss: 1.31261, val_acc: 0.53371\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch43] time: 0m 1s \t loss: 0.99839, acc: 0.58216 | val_loss: 1.21779, val_acc: 0.55618\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch44] time: 0m 1s \t loss: 0.98960, acc: 0.57584 | val_loss: 1.14833, val_acc: 0.57022\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch45] time: 0m 1s \t loss: 0.94870, acc: 0.58076 | val_loss: 1.20729, val_acc: 0.57303\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch46] time: 0m 1s \t loss: 0.90347, acc: 0.61025 | val_loss: 1.14267, val_acc: 0.54775\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch47] time: 0m 1s \t loss: 0.92972, acc: 0.61447 | val_loss: 1.19454, val_acc: 0.51966\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch48] time: 0m 1s \t loss: 0.96574, acc: 0.58287 | val_loss: 1.27584, val_acc: 0.57303\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \r"]},{"name":"stdout","output_type":"stream","text":["[Epoch49] time: 0m 1s \t loss: 0.89536, acc: 0.61306 | val_loss: 1.07941, val_acc: 0.53933\n"]},{"name":"stderr","output_type":"stream","text":["                                                  "]},{"name":"stdout","output_type":"stream","text":["[Epoch50] time: 0m 1s \t loss: 0.85811, acc: 0.62430 | val_loss: 1.13345, val_acc: 0.51966\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["import time\n","\n","# 최대 Epoch을 지정합니다.\n","num_epochs = 50\n","\n","min_loss = np.inf\n","\n","STATE_DICT_PATH = \"BBC-Text-Classification.pth\"\n","\n","# Epoch 별 훈련 및 검증을 수행합니다.\n","for epoch in range(num_epochs):\n","    # Model Training\n","    # 훈련 손실과 정확도를 반환 받습니다.\n","    start = time.time()\n","    train_loss, train_acc = fit(\n","        model, train_loader, loss_fn, optimizer, device, phase=\"train\"\n","    )\n","\n","    # 검증 손실과 검증 정확도를 반환 받습니다.\n","    val_loss, val_acc = fit(\n","        model, validation_loader, loss_fn, optimizer, device, phase=\"eval\"\n","    )\n","\n","    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n","    if val_loss < min_loss:\n","        print(\n","            f\"[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!\"\n","        )\n","        min_loss = val_loss\n","        torch.save(model.state_dict(), STATE_DICT_PATH)\n","\n","    time_elapsed = time.time() - start\n","    # Epoch 별 결과를 출력합니다.\n","    print(\n","        f\"[Epoch{epoch+1:02d}] time: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s \\t loss: {train_loss:.5f}, acc: {train_acc:.5f} | val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}\"\n","    )"]},{"cell_type":"markdown","id":"ef40913c","metadata":{"id":"ef40913c"},"source":["## 저장한 가중치 로드\n"]},{"cell_type":"code","execution_count":null,"id":"c5473a43","metadata":{"id":"c5473a43","outputId":"1bf6d2c2-1ee6-4105-f20c-c9b7ff4f2429"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["# 모델에 저장한 가중치를 로드합니다.\n","model.load_state_dict(torch.load(STATE_DICT_PATH))"]},{"cell_type":"markdown","id":"44d859e9","metadata":{"id":"44d859e9"},"source":["## 최종 검증 손실 및 정확도 출력\n"]},{"cell_type":"code","execution_count":null,"id":"cbb76e89","metadata":{"id":"cbb76e89","outputId":"49e835ca-2fd7-424b-85ed-5a57559caf29"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                         "]},{"name":"stdout","output_type":"stream","text":["\n","evaluation loss: 0.99721, evaluation accuracy: 0.56742\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["# 최종 검증 손실(validation loss)와 검증 정확도(validation accuracy)를 산출합니다.\n","final_loss, final_acc = fit(\n","    model, validation_loader, loss_fn, optimizer, device, phase=\"eval\"\n",")\n","print(\n","    f\"\\nevaluation loss: {final_loss:.5f}, evaluation accuracy: {final_acc:.5f}\")"]},{"cell_type":"markdown","id":"b06e4b85","metadata":{"id":"b06e4b85"},"source":["## 예측코드\n"]},{"cell_type":"code","execution_count":null,"id":"ebe47b0d","metadata":{"id":"ebe47b0d"},"outputs":[],"source":["predictions = []\n","model = model.to(device)\n","# 검증모드 진입\n","model.eval()\n","\n","with torch.no_grad():\n","    # loss 초기화\n","    running_loss = 0\n","    # 정확도 계산\n","    running_acc = 0\n","    for x in test_loader:\n","        x = x.to(device)\n","        model.init_hidden_and_cell_state(len(x), device)\n","        y_hat = model(x)\n","        label = y_hat.argmax(dim=1).detach().item()\n","        predictions.append(label)"]},{"cell_type":"code","execution_count":null,"id":"de27daac","metadata":{"id":"de27daac","outputId":"13261fd2-a5e0-4e70-a217-7cec2856075f"},"outputs":[{"data":{"text/plain":["{0: 'business', 1: 'sport', 2: 'politics', 3: 'tech', 4: 'entertainment'}"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["idx_to_label = {idx: lbl for lbl, idx in label_map.items()}\n","idx_to_label"]},{"cell_type":"code","execution_count":null,"id":"fcd95960","metadata":{"id":"fcd95960","outputId":"bbb46a24-bb51-4d89-e616-a933f827b592"},"outputs":[{"data":{"text/plain":["['politics', 'politics', 'politics', 'politics', 'business']"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["your_answer = [idx_to_label[p] for p in predictions]\n","your_answer[:5]"]},{"cell_type":"markdown","id":"9bc59707","metadata":{"id":"9bc59707"},"source":["## 결과 제출\n","\n","- 느리다고 중지 후 다시 평가 코드를 실행하는 경우 제출 과정에서 패널티가 발생할 수 있습니다. (제출 횟수 이슈 발생 가능)\n","- 제출결과는 [대회페이지](http://braincrew2.iptime.org:8001/competitions/BBCTEXT/)의 `리더보드` 와 `제출` 탭에서 확인할 수 있습니다.\n"]},{"cell_type":"markdown","id":"dba5d858","metadata":{"id":"dba5d858"},"source":["아래 Cell을 실행하여 예측 결과 업데이트\n"]},{"cell_type":"code","execution_count":null,"id":"c694fba8","metadata":{"id":"c694fba8","outputId":"07b55d53-f3f2-4d23-ac9b-84a4431bfab7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>business</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>440</th>\n","      <td>politics</td>\n","    </tr>\n","    <tr>\n","      <th>441</th>\n","      <td>business</td>\n","    </tr>\n","    <tr>\n","      <th>442</th>\n","      <td>entertainment</td>\n","    </tr>\n","    <tr>\n","      <th>443</th>\n","      <td>business</td>\n","    </tr>\n","    <tr>\n","      <th>444</th>\n","      <td>sport</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>445 rows × 1 columns</p>\n","</div>"],"text/plain":["             label\n","0         politics\n","1         politics\n","2         politics\n","3         politics\n","4         business\n","..             ...\n","440       politics\n","441       business\n","442  entertainment\n","443       business\n","444          sport\n","\n","[445 rows x 1 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["아이디:  sample@test.com\n","파일명:  submissions/20240227-175327-submission.csv\n","============================================================\n","[제출에 성공하였습니다]\n","제출 결과: 0.5325842696629214\n"]}],"source":["import competition\n","\n","# 예측 결과 업데이트\n","submission = pd.read_csv(os.path.join(DATA_DIR, \"submission.csv\"))\n","submission[\"label\"] = your_answer\n","\n","display(submission)\n","competition.submit(project, username, password, submission)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[{"file_id":"1fZlxv-yHxVu9Xw7NTj8Ae0s4LF852Hge","timestamp":1709369552476}]}},"nbformat":4,"nbformat_minor":5}