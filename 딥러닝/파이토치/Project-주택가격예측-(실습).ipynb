{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "if not os.path.exists(\"competition.py\"):\n",
    "    url = \"https://link.teddynote.com/COMPT\"\n",
    "    file_name = \"competition.py\"\n",
    "    response = requests.get(url)\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "import competition\n",
    "\n",
    "# 파일 다운로드\n",
    "# competition.download_competition_files(project)\n",
    "competition.download_competition_files(\n",
    "    \"https://link.teddynote.com/ADVHOUSE\", use_competition_url=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Data 경로 설정\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋 로드 (train.csv)\n",
    "train = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "\n",
    "# test 데이터셋 로드 (test.csv)\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "\n",
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "all_data.head()\n",
    "\n",
    "numeric_columns = all_data.select_dtypes(exclude=\"object\")\n",
    "numeric_columns\n",
    "\n",
    "numeric_columns = numeric_columns.fillna(0)\n",
    "numeric_columns\n",
    "\n",
    "train_data = numeric_columns[: len(train)]\n",
    "test_data = numeric_columns[len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop(\"SalePrice\", axis=1)\n",
    "y_train = train_data[\"SalePrice\"]\n",
    "\n",
    "x_test = test_data.drop(\"SalePrice\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomDataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y=None, normalize=True):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        # 데이터 표준화\n",
    "        if normalize:\n",
    "            scaler = StandardScaler()\n",
    "            self.x = pd.DataFrame(scaler.fit_transform(self.x))\n",
    "\n",
    "        # 텐서 변환\n",
    "        self.x = torch.tensor(self.x.values).float()\n",
    "\n",
    "        if y is not None:\n",
    "            self.y = torch.tensor(self.y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        if self.y is not None:\n",
    "            y = self.y[idx]\n",
    "            return x, y\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) import\n",
    "import torch: PyTorch 라이브러리를 가져옵니다.\n",
    "from torch.utils.data import Dataset: PyTorch의 사용자 정의 데이터 세트에 대한 기본 클래스인 PyTorch에서 Dataset 클래스를 가져옵니다.\n",
    "from sklearn.preprocessing import StandardScaler: 데이터 표준화에 사용되는 scikit-learn에서 StandardScaler를 가져옵니다.\n",
    "\n",
    "2) CustomDataset 클래스:\n",
    "\n",
    "이 클래스는 torch.utils.data.Dataset에서 상속되는 사용자 정의 데이터세트 클래스로, PyTorch의 데이터 로딩 유틸리티와 호환됩니다.\n",
    "\n",
    "3) 생성자 메서드(__init__):\n",
    "\n",
    "def __init__(self, x, y=None, Normalize=True):: CustomDataset 클래스를 초기화합니다. 'x'(기능) 및 'y'(대상)를 입력으로 사용하며, 여기서 'y'는 선택 사항입니다.\n",
    "super(CustomDataset, self).__init__(): 상위 클래스(Dataset)의 생성자를 호출합니다.\n",
    "self.x = x 및 self.y = y: 입력 특성과 대상을 인스턴스 변수에 할당합니다.\n",
    "데이터 표준화:\n",
    "normalize가 True인 경우 scikit-learn의 StandardScaler를 사용하여 입력 기능을 표준화합니다.\n",
    "\n",
    "텐서 변환:\n",
    "표준화된 기능(self.x)을 float 유형의 PyTorch 텐서로 변환합니다.\n",
    "y가 제공되면(None 아님) 대상(self.y)도 float 유형의 PyTorch 텐서로 변환됩니다.\n",
    "\n",
    "\n",
    "4) __len__ 방법:\n",
    "\n",
    "\n",
    "def __len__(self):: 데이터세트의 길이, 즉 샘플 수를 정의합니다. 입력 특성(self.x)의 길이를 반환합니다.\n",
    "\n",
    "5) __getitem__ 메소드:\n",
    "\n",
    "\n",
    "def __getitem__(self, idx):: 인덱스 idx가 지정된 데이터 세트에서 샘플을 검색합니다.\n",
    "x = self.x[idx]: idx 인덱스에 해당하는 특징을 검색합니다.\n",
    "y가 제공되는 경우(None 아님):\n",
    "y = self.y[idx]: idx 인덱스에 해당하는 대상을 검색합니다.\n",
    "샘플의 특징과 대상을 나타내는 튜플 (x, y)를 반환합니다.\n",
    "\n",
    "y를 제공하지 않으면(None) 기능만 반환합니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
